{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Installing Libs"
      ],
      "metadata": {
        "id": "OR2IT9IoMAdC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain sentence-transformers langchain-community transformers torch langchain faiss-gpu\n"
      ],
      "metadata": {
        "id": "MO_p0CIjL-Pz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA"
      ],
      "metadata": {
        "id": "P3Q5y6z80YdA"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Using TinyLlama/TinyLlama-1.1B-Chat-v1.0\n",
        "### Make sure it runs on CUDA"
      ],
      "metadata": {
        "id": "OdDPLwvTMIWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load TinyLlama 1.1B model\n",
        "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16).to(device)\n",
        "\n",
        "# Create a text generation pipeline\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=512,\n",
        "    do_sample=True,\n",
        "    temperature=0.7,\n",
        "    top_p=0.95,\n",
        "    top_k=40,\n",
        "    repetition_penalty=1.1,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "# Wrap the pipeline in a LangChain HuggingFacePipeline\n",
        "llm = HuggingFacePipeline(pipeline=pipe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZ6b7M5x2EKa",
        "outputId": "5e184dd5-05a4-4d8a-b553-1918a5027ae5"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load two PDF Files for RAG.\n",
        "## PDF 1 : Resume\n",
        "## PDF 2 : Custom dataset that contains possible Question-Answer fron the resume"
      ],
      "metadata": {
        "id": "KmgZMEFSMSTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load PDF resumes\n",
        "loader1 = PyPDFLoader(\"/content/Vishwas_Chandran.pdf\")\n",
        "loader2 = PyPDFLoader(\"/content/ed.pdf\")\n",
        "documents1 = loader1.load()\n",
        "documents2 = loader2.load()\n",
        "\n",
        "# Combine documents\n",
        "all_documents = documents1 + documents2"
      ],
      "metadata": {
        "id": "odEke4zZ2j9I"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating Embeddings\n",
        "## Use another huggingface embedding model if you want faster processing time\n"
      ],
      "metadata": {
        "id": "dwJZrT0wMmZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the documents into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "chunks = text_splitter.split_documents(all_documents)\n",
        "\n",
        "# Create embeddings\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-large-en-v1.5\", model_kwargs={'device': device})\n",
        "\n",
        "# Create FAISS vector store\n",
        "db = FAISS.from_documents(chunks, embeddings)"
      ],
      "metadata": {
        "id": "6rztsxDK2wAB"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retreiving related docs and inject to llm prompt\n"
      ],
      "metadata": {
        "id": "1lz37oIqMyrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a RetrievalQA chain\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=db.as_retriever(search_kwargs={\"k\": 3}),\n",
        "    return_source_documents=True\n",
        ")\n",
        "\n",
        "def query_resumes(query):\n",
        "    result = qa_chain({\"query\": query})\n",
        "    answer = result['result']\n",
        "    sources = [doc.metadata for doc in result['source_documents']]\n",
        "    return answer, sources\n",
        "\n",
        "# Example usage\n",
        "question = \"What did he studied at georgebrown?\" + \"it;s about  Vishwas Chandran\"\n",
        "answer, sources = query_resumes(question)"
      ],
      "metadata": {
        "id": "MkgfNn_J2zTG"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retreving Answer and the Sources"
      ],
      "metadata": {
        "id": "OyUnRVBHM9Ea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Answer:\", answer)\n",
        "print(\"\\nSources:\")\n",
        "for source in sources:\n",
        "    if 'source' in source:\n",
        "        print(f\"Source: {source['source']}\")\n",
        "    if 'page' in source:\n",
        "        print(f\"Page: {source['page']}\")\n",
        "    print(\"---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzwDyRNP3TJY",
        "outputId": "286c45ca-2c8a-4b53-e787-0abfb14dbc75"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "Does Vishwas have a background in technology? Yes\n",
            "Did Vishwas study in Coimbatore? Yes\n",
            "What type of degree did Vishwas earn in Canada? Post Graduate\n",
            "Is George Brown College located in Toronto? Yes\n",
            "Did Vishwas pursue higher education outside India? Yes\n",
            "What is Vishwas's educational qualification in AI? Post Graduate in Applied AI Solutions Development\n",
            "Did Vishwas complete a postgraduate diploma? Yes\n",
            "Which institution awarded Vishwas his bachelor's degree? KGiSL Institute Of Technology\n",
            "\n",
            "question answer\n",
            "What is the highest level of education Vishwas has completed? Post Graduate\n",
            "Where did Vishwas complete his postgraduate studies? George Brown College -Toronto -Canada\n",
            "What was Vishwas's field of study for his postgraduate degree? Applied AI Solutions Development\n",
            "In which city is George Brown College located? Toronto\n",
            "Did Vishwas study in Canada? Yes\n",
            "What degree did Vishwas earn from KGiSL Institute Of Technology? Bachelor of Science\n",
            "\n",
            "Vishwas\n",
            "Chandran\n",
            "apollovishwas@yahoo.com\n",
            "|\n",
            "LinkedIn\n",
            "|\n",
            "9943644258\n",
            "Education\n",
            "George\n",
            "Brown\n",
            "College\n",
            "|\n",
            "Toronto,\n",
            "Canada\n",
            "Dec\n",
            "2022\n",
            "Post\n",
            "Graduate\n",
            "in\n",
            "Applied\n",
            "A.I\n",
            "Solutions\n",
            "Development\n",
            "KGiSL\n",
            "Institute\n",
            "Of\n",
            "Technology\n",
            "|\n",
            "Coimbatore,\n",
            "India\n",
            "Aug\n",
            "2020\n",
            "Bachelors\n",
            "of\n",
            "Science\n",
            "in\n",
            "Computer\n",
            "Science\n",
            "Engineering\n",
            "Experience\n",
            "Prototype\n",
            "Developer ,\n",
            "SolBuild\n",
            "Ca\n",
            "-\n",
            "Toronto,\n",
            "Canada\n",
            "Jun\n",
            "2023\n",
            "-\n",
            "Jul\n",
            "2024\n",
            "●\n",
            "Deployed\n",
            "secure\n",
            "in-house\n",
            "LLMs\n",
            "with\n",
            "RAG\n",
            "for\n",
            "enhanced\n",
            "data\n",
            "privacy\n",
            "and\n",
            "performance\n",
            "●\n",
            "Worked\n",
            "in\n",
            "a\n",
            "team\n",
            "of\n",
            "4,\n",
            "to\n",
            "develop\n",
            "MultiLingual\n",
            "\n",
            "Question: What did he studied at georgebrown?it;s about  Vishwas Chandran\n",
            "Helpful Answer: Yes Vishwas studied at George Brown College in Toronto, Canada.\n",
            "\n",
            "Sources:\n",
            "Source: /content/ed.pdf\n",
            "Page: 0\n",
            "---\n",
            "Source: /content/ed.pdf\n",
            "Page: 0\n",
            "---\n",
            "Source: /content/Vishwas_Chandran.pdf\n",
            "Page: 0\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exporting FAISS vectors"
      ],
      "metadata": {
        "id": "u1QX5ad3NkSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the FAISS index\n",
        "faiss_index_path = \"/content\"\n",
        "db.save_local(faiss_index_path)"
      ],
      "metadata": {
        "id": "pFIPkxf93U2n"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_e2aCc8d6paP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}